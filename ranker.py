# File: ranker.py
import os
import json
import subprocess


def query_ollama(prompt, model="llama3.1:8b"):
    result = subprocess.run(
        ["ollama", "run", model],
        input=prompt,
        capture_output=True,
        text=True,
        encoding="utf-8",
        errors="replace"
    )
    return result.stdout.strip()


def rate_clips(srt_folder, output_file="clip_ratings.json"):
    results = []

    for file in os.listdir(srt_folder):
        if file.endswith(".srt"):
            srt_path = os.path.join(srt_folder, file)

            with open(srt_path, "r", encoding="utf-8") as f:
                subtitles = f.read()

            prompt = f"""
You are a content critic. Given the subtitles of a short video clip, 
rate how entertaining it is for a general TikTok audience. Remember, TikTok viewers have short attention spans and prefer engaging, funny, or surprising content.
Do not rate clips highly if they don't make sense without context. Don't rate clips highly if anyone uses slurs or offensive language. (glorifying violence etc)
I want the "setup" and "punchline" of a joke to be in the same clip.
Subtitles of the clip:
---
{subtitles}
---

Respond in JSON only with two fields:
- "rating" (float 1.00-100.00, 100.00 = most entertaining)
- "reason" (short explanation, one sentence max)
"""

            print(f"Querying LLM for {file}...")
            response = query_ollama(prompt)

            try:
                data = json.loads(response)
            except json.JSONDecodeError:
                data = {"rating": None, "reason": response}

            results.append({"clip": file, **data})

    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(results, f, indent=2, ensure_ascii=False)

    print(f"Ratings saved to {output_file}")


def _srt_to_text_with_timestamps(srt_content):
    """Parse a simple SRT content into a list of (start_seconds, end_seconds, text).

    This is a lightweight parser that expects the common SRT blocks:
    index\nstart --> end\ntext\n\n
    Not a full spec parser, but good enough for short transcripts generated by this project.
    """
    import re

    entries = []
    blocks = re.split(r"\n\s*\n", srt_content.strip())
    time_re = re.compile(r"(\d{2}):(\d{2}):(\d{2}),(\d{3})\s*-->\s*(\d{2}):(\d{2}):(\d{2}),(\d{3})")

    def to_seconds(h, m, s, ms):
        return int(h) * 3600 + int(m) * 60 + int(s) + int(ms) / 1000.0

    for block in blocks:
        lines = block.strip().splitlines()
        if len(lines) >= 2:
            # first line could be index
            if time_re.search(lines[0]):
                time_line = lines[0]
                text_lines = lines[1:]
            else:
                time_line = lines[1]
                text_lines = lines[2:]

            m = time_re.search(time_line)
            if not m:
                continue

            start = to_seconds(m.group(1), m.group(2), m.group(3), m.group(4))
            end = to_seconds(m.group(5), m.group(6), m.group(7), m.group(8))
            text = " ".join(l.strip() for l in text_lines if l.strip())
            entries.append((start, end, text))

    return entries


def rate_full_transcript(srt_path, output_file="clip_ratings.json", model="llama3.1:8b"):
    """Read an entire SRT transcript and ask the LLM to pick the single most entertaining moment.

    Behavior:
    - Loads the SRT file as one transcript with timestamps.
    - Sends the transcript to the LLM and asks it to reply with a JSON object containing:
        - "best_timestamp" (seconds, integer) representing the recommended start time for a short clip
        - "window_seconds" (int) how long the clip should be (suggested 10-20)
        - "reason" (one-sentence)

    The prompt instructs the model to pick a timestamp that is within 5-15 seconds of a minute mark
    (e.g., near 00:01:00, 00:02:00, etc.) when possible, to better align with platform-friendly minute boundaries.

    The function writes a single JSON object to `output_file`.
    """
    with open(srt_path, "r", encoding="utf-8") as f:
        srt_content = f.read()

    entries = _srt_to_text_with_timestamps(srt_content)

    # Flatten transcript into a single text blob but keep markers for timestamps every 30-60s for the model.
    flattened = []
    for start, end, text in entries:
        flattened.append(f"[{int(start)}-{int(end)}] {text}")

    transcript_blob = "\n".join(flattened)

    prompt = f"""
You are a content critic that only responds in JSON. Given a full video transcript with timestamps, pick the single best moment
that would make the most entertaining short clip for a general TikTok audience. TikTok viewers prefer engaging, funny, or surprising
moments. Prefer moments that are near minute marks to help editing logistics: choose a timestamp within 5-15 seconds before or after
an exact minute (for example 00:01:05 or 00:00:55 is acceptable for the 1 minute mark). If no good moment falls near a minute mark,
you may pick any other timestamp.

Transcript (format: [start-end] text):
---
{transcript_blob}
---

Respond in JSON only with these fields:
- "best_timestamp": integer seconds where a clip should start
- "window_seconds": integer duration in seconds for the clip (suggest 8-20)
- "reason": one sentence explaining why
"""

    print(f"Querying LLM for full transcript {os.path.basename(srt_path)}...")
    response = query_ollama(prompt, model=model)

    try:
        data = json.loads(response)
    except json.JSONDecodeError:
        data = {"best_timestamp": None, "window_seconds": None, "reason": response}

    output = {"transcript_file": os.path.basename(srt_path), **data}

    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(output, f, indent=2, ensure_ascii=False)

    print(f"Full-transcript rating saved to {output_file}")

    return output


def pick_dynamic_segments(srt_path, num_segments=5, target_duration=60, model="llama3.1:8b"):
    """Pick multiple dynamic ~1-minute segments from a full transcript.
    
    Args:
        srt_path: Path to the full transcript SRT file
        num_segments: Number of segments to pick (default 5)
        target_duration: Target duration in seconds (default 60)
        model: Ollama model to use
    
    Returns:
        List of dicts with keys: start_seconds, duration_seconds, rating, reason
    """
    with open(srt_path, "r", encoding="utf-8") as f:
        srt_content = f.read()
    
    entries = _srt_to_text_with_timestamps(srt_content)
    
    # Flatten transcript with timestamps
    flattened = []
    for start, end, text in entries:
        flattened.append(f"[{int(start)}-{int(end)}] {text}")
    
    transcript_blob = "\n".join(flattened)
    
    prompt = f"""
You are a content critic that only responds in JSON. Given a full video transcript with timestamps, pick the {num_segments} best moments
that would make the most entertaining short clips for a general TikTok audience. TikTok viewers prefer engaging, funny, or surprising
moments. Each clip should be approximately {target_duration} seconds long, but you can adjust the start time and duration slightly
to capture complete thoughts, jokes, or moments (e.g., start at 0:12 and go to 1:05 if that captures a complete moment better than
starting at 0:00 and going to 1:00).

Transcript (format: [start-end] text):
---
{transcript_blob}
---

Respond in JSON only with a single array called "segments". Each element should have:
- "start_seconds": integer seconds where the clip should start (can be any timestamp, not just minute marks)
- "duration_seconds": integer duration in seconds (target {target_duration}, but can be 45-75 seconds to capture complete moments)
- "rating": float 1.00-100.00 indicating how entertaining this segment is
- "reason": one sentence explaining why this moment is entertaining

Pick {num_segments} distinct segments that don't overlap significantly. Order them by rating (best first).
"""
    
    print(f"Querying LLM to pick {num_segments} dynamic segments from {os.path.basename(srt_path)}...")
    response = query_ollama(prompt, model=model)
    
    # Extract JSON from markdown code blocks if present
    import re
    json_match = re.search(r'```(?:json)?\s*(\[.*?\])\s*```', response, re.DOTALL)
    if json_match:
        json_str = json_match.group(1)
    else:
        # Try to find JSON array directly
        json_match = re.search(r'(\[.*?\])', response, re.DOTALL)
        if json_match:
            json_str = json_match.group(1)
        else:
            json_str = response
    
    # Try to fix incomplete JSON (common when response is cut off)
    # If the JSON is incomplete, try to extract what we can
    if not json_str.strip().endswith(']'):
        # Find the last complete segment
        last_complete = json_str.rfind('}')
        if last_complete > 0:
            # Try to close the array
            json_str = json_str[:last_complete + 1] + ']'
    
    try:
        data = json.loads(json_str)
        # Handle both formats: direct array or wrapped in object
        if isinstance(data, list):
            segments = data
        elif isinstance(data, dict) and "segments" in data:
            segments = data["segments"]
        else:
            # Try to extract array from response
            segments = [data] if "start_seconds" in data else []
        
        # Validate and sort segments
        valid_segments = []
        for seg in segments:
            if "start_seconds" in seg and "duration_seconds" in seg:
                valid_segments.append({
                    "start_seconds": int(seg.get("start_seconds", 0)),
                    "duration_seconds": int(seg.get("duration_seconds", target_duration)),
                    "rating": float(seg.get("rating", 50.0)),
                    "reason": seg.get("reason", "No reason provided")
                })
        
        # Sort by rating descending
        valid_segments.sort(key=lambda x: x["rating"], reverse=True)
        
        print(f"Picked {len(valid_segments)} dynamic segments")
        return valid_segments
        
    except json.JSONDecodeError as e:
        print(f"Error parsing LLM response: {e}")
        print(f"Attempted to parse: {json_str[:500]}")
        print(f"Full response was: {response[:1000]}")
        return []


